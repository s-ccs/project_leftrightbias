@online{noauthor_about_nodate,
	title = {About – {PyGaze}},
	url = {https://www.pygaze.org/about/},
	urldate = {2025-03-31},
	langid = {british},
}

@article{cludius_attentional_2019,
	title = {Attentional biases of vigilance and maintenance in obsessive-compulsive disorder: An eye-tracking study},
	volume = {20},
	issn = {2211-3649},
	url = {https://www.sciencedirect.com/science/article/pii/S2211364917300970},
	doi = {10.1016/j.jocrd.2017.12.007},
	series = {Experimental studies of cognitive processes in {OCD} – new insights and challenges},
	shorttitle = {Attentional biases of vigilance and maintenance in obsessive-compulsive disorder},
	abstract = {Background and objectives
Attentional biases play an important role in the development and maintenance of obsessive-compulsive disorder ({OCD}). Previous studies using reaction time tasks in {OCD} have produced inconsistent results. This is the first study to measure attentional biases in patients with several subtypes of {OCD} using eye tracking.
Methods
Twenty-eight patients with {OCD} and 21 healthy controls were assessed using a free-viewing paradigm, incorporating contamination-related, checking-related, and neutral stimuli. Attentional patterns were measured using an eye tracker. A possible vigilance bias was assessed using entry time, and a possible maintenance bias was assessed using dwell time.
Results
Patients with checking-related symptoms of {OCD} showed a maintenance bias but no vigilance bias in regard to checking-related compared to neutral stimuli. No differences in attention were found in patients with contamination-related symptoms.
Limitations
Internal validity is restricted due to a high overlap between subgroups, the lack of negative (not {OCD}-related) control stimuli, and the absence of a clinical control group.
Conclusions
Patients with checking-related symptoms of {OCD} showed a maintenance bias to checking-related stimuli. Due to methodological limitations, the results should be considered preliminary and need to be replicated before firm conclusions can be drawn.},
	pages = {30--38},
	journaltitle = {Journal of Obsessive-Compulsive and Related Disorders},
	shortjournal = {Journal of Obsessive-Compulsive and Related Disorders},
	author = {Cludius, Barbara and Wenzlaff, Frederike and Briken, Peer and Wittekind, Charlotte E.},
	urldate = {2023-03-15},
	date = {2019-01-01},
	langid = {english},
	keywords = {Attentional bias, Eye movements, Eye tracking, Obsessive-compulsive disorder},
}

@article{mathot_conducting_2022,
	title = {Conducting Linguistic Experiments Online With {OpenSesame} and {OSWeb}},
	volume = {72},
	issn = {0023-8333, 1467-9922},
	url = {https://onlinelibrary.wiley.com/doi/10.1111/lang.12509},
	doi = {10.1111/lang.12509},
	abstract = {Abstract
            In this Methods Showcase Article, we outline a workflow for running behavioral experiments online, with a focus on experiments that rely on presentation of complex stimuli and measurement of reaction times, which includes many psycholinguistic experiments. The workflow that we describe here relies on three tools: {OpenSesame}/{OSWeb} (open source) provides a user‐friendly graphical interface for developing experiments; {JATOS} (open source) is server software for hosting experiments; and Prolific (commercial) is a platform for recruiting participants. These three tools integrate well with each other and together provide a workflow that requires little technical expertise. We discuss, and illustrate through an example study, several challenges that are associated with running online experiments, including temporal precision, the implementation of counterbalancing, data quality, and issues related to privacy and ethics. We conclude that these challenges are real but surmountable, and that in many cases online experiments are a viable alternative to laboratory‐based experiments.},
	pages = {1017--1048},
	number = {4},
	journaltitle = {Language Learning},
	shortjournal = {Language Learning},
	author = {Mathôt, Sebastiaan and March, Jennifer},
	urldate = {2025-03-31},
	date = {2022-12},
	langid = {english},
}

@article{hernandez_escaping_2017,
	title = {Escaping the corner of death? An eye-tracking study of reading direction influence on attention and memory},
	volume = {34},
	rights = {https://www.emerald.com/insight/site-policies},
	issn = {0736-3761},
	url = {https://www.emerald.com/insight/content/doi/10.1108/JCM-02-2016-1710/full/html},
	doi = {10.1108/JCM-02-2016-1710},
	shorttitle = {Escaping the corner of death?},
	abstract = {Purpose: We examine the effect of location-driven logo placement on attention and memory on the web addressing differences between individuals that read unidirectionally (left-to-right) versus bidirectionally (both right-to-left and left-to-right). Design/methodology/approach: Using an eye-tracking approach combined with traditional verbal measures, we compared attention and memory measures from a sample composed of bidirectional (Arab/English) readers and unidirectional readers. Findings: The findings reveal that unidirectional and bidirectional readers differ in attention patterns. Compared to bidirectional readers, unidirectional readers pay less attention to the logo on the bottom right corner of the webpage based on verbal measures. The eye-tracking data of the two groups further identify differences based on total hits and duration time. Unidirectional left-to-right readers demonstrate higher fluency in feature-based attention whereas bidirectional readers show higher fluency in spatial attention. Research limitations: Individuals from the sampled cultures would have a considerably different mindset regarding exposure to pictorial materials in general. Future research that replicates or extends the current study needs to ensure comparability via both cultural-psychological and demographic analyses. Practical implications: The findings suggest that directional reading bias should be taken into consideration in web design, online advertising and search patterns in an international marketing context.},
	pages = {1--10},
	number = {1},
	journaltitle = {Journal of Consumer Marketing},
	shortjournal = {{JCM}},
	author = {Hernandez, Monica D. and Wang, Yong and Sheng, Hong and Kalliny, Morris and Minor, Michael},
	urldate = {2024-12-02},
	date = {2017-01-09},
	langid = {english},
}

@article{glaholt_evidence_2010,
	title = {Evidence for top-down control of eye movements during visual decision making},
	volume = {10},
	issn = {1534-7362},
	url = {https://doi.org/10.1167/10.5.15},
	doi = {10.1167/10.5.15},
	abstract = {Participants' eye movements were monitored while they viewed displays containing 6 exemplars from one of several categories of everyday items (belts, sunglasses, shirts, shoes), with a column of 3 items presented on the left and another column of 3 items presented on the right side of the display. Participants were either required to choose which of the two sets of 3 items was the most expensive (2-{AFC}) or which of the 6 items was the most expensive (6-{AFC}). Importantly, the stimulus display, and the relevant stimulus dimension, were held constant across conditions. Consistent with the hypothesis of top-down control of eye movements during visual decision making, we documented greater selectivity in the processing of stimulus information in the 6-{AFC} than the 2-{AFC} decision. In addition, strong spatial biases in looking behavior were demonstrated, but these biases were largely insensitive to the instructional manipulation, and did not substantially influence participants' choices.},
	pages = {15},
	number = {5},
	journaltitle = {Journal of Vision},
	shortjournal = {Journal of Vision},
	author = {Glaholt, Mackenzie G. and Wu, Mei-Chun and Reingold, Eyal M.},
	urldate = {2024-11-21},
	date = {2010-05-07},
}

@article{nummenmaa_eye_2006,
	title = {Eye movement assessment of selective attentional capture by emotional pictures.},
	volume = {6},
	issn = {1931-1516, 1528-3542},
	url = {https://doi.apa.org/doi/10.1037/1528-3542.6.2.257},
	doi = {10.1037/1528-3542.6.2.257},
	abstract = {The eye-tracking method was used to assess attentional orienting to and engagement on emotional visual scenes. In Experiment 1, unpleasant, neutral, or pleasant target pictures were presented simultaneously with neutral control pictures in peripheral vision under instruction to compare pleasantness of the pictures. The probability of first fixating an emotional picture, and the frequency of subsequent fixations, were greater than those for neutral pictures. In Experiment 2, participants were instructed to avoid looking at the emotional pictures, but these were still more likely to be fixated first and gazed longer during the first-pass viewing than neutral pictures. Low-level visual features cannot explain the results. It is concluded that overt visual attention is captured by both unpleasant and pleasant emotional content.},
	pages = {257--268},
	number = {2},
	journaltitle = {Emotion},
	shortjournal = {Emotion},
	author = {Nummenmaa, Lauri and Hyönä, Jukka and Calvo, Manuel G.},
	urldate = {2024-11-26},
	date = {2006},
	langid = {english},
}

@article{hernandez-garcia_global_2020,
	title = {Global visual salience of competing stimuli},
	volume = {20},
	issn = {1534-7362},
	url = {https://doi.org/10.1167/jov.20.7.27},
	doi = {10.1167/jov.20.7.27},
	abstract = {Current computational models of visual salience accurately predict the distribution of fixations on isolated visual stimuli. It is not known, however, whether the global salience of a stimulus, that is, its effectiveness in the competition for attention with other stimuli, is a function of the local salience or an independent measure. Further, do task and familiarity with the competing images influence eye movements? Here, we investigated the direction of the first saccade to characterize and analyze the global visual salience of competing stimuli. Participants freely observed pairs of images while eye movements were recorded. The pairs balanced the combinations of new and already seen images, as well as task and task-free trials. Then, we trained a logistic regression model that accurately predicted the location—left or right image—of the first fixation for each stimulus pair, accounting too for the influence of task, familiarity, and lateral bias. The coefficients of the model provided a reliable measure of global salience, which we contrasted with two distinct local salience models, {GBVS} and Deep Gaze. The lack of correlation of the behavioral data with the former and the small correlation with the latter indicate that global salience cannot be explained by the feature-driven local salience of images. Further, the influence of task and familiarity was rather small, and we reproduced the previously reported left-sided bias. Summarized, we showed that natural stimuli have an intrinsic global salience related to the human initial gaze direction, independent of the local salience and little influenced by task and familiarity.},
	pages = {27},
	number = {7},
	journaltitle = {Journal of Vision},
	shortjournal = {Journal of Vision},
	author = {Hernández-García, Alex and Ramos Gameiro, Ricardo and Grillini, Alessandro and König, Peter},
	urldate = {2024-11-21},
	date = {2020-07-28},
}

@article{mathot_opensesame_2012,
	title = {{OpenSesame}: An open-source, graphical experiment builder for the social sciences},
	volume = {44},
	issn = {1554-3528},
	url = {http://link.springer.com/10.3758/s13428-011-0168-7},
	doi = {10.3758/s13428-011-0168-7},
	shorttitle = {{OpenSesame}},
	pages = {314--324},
	number = {2},
	journaltitle = {Behavior Research Methods},
	shortjournal = {Behav Res},
	author = {Mathôt, Sebastiaan and Schreij, Daniel and Theeuwes, Jan},
	urldate = {2025-03-31},
	date = {2012-06},
	langid = {english},
}

@article{peirce_psychopy2_2019,
	title = {{PsychoPy}2: Experiments in behavior made easy},
	volume = {51},
	issn = {1554-3528},
	url = {http://link.springer.com/10.3758/s13428-018-01193-y},
	doi = {10.3758/s13428-018-01193-y},
	shorttitle = {{PsychoPy}2},
	pages = {195--203},
	number = {1},
	journaltitle = {Behavior Research Methods},
	shortjournal = {Behav Res},
	author = {Peirce, Jonathan and Gray, Jeremy R. and Simpson, Sol and {MacAskill}, Michael and Höchenberger, Richard and Sogo, Hiroyuki and Kastman, Erik and Lindeløv, Jonas Kristoffer},
	urldate = {2025-03-31},
	date = {2019-02},
	langid = {english},
}

@article{dalmaijer_pygaze_2014,
	title = {{PyGaze}: An open-source, cross-platform toolbox for minimal-effort programming of eyetracking experiments},
	volume = {46},
	issn = {1554-3528},
	url = {https://link.springer.com/10.3758/s13428-013-0422-2},
	doi = {10.3758/s13428-013-0422-2},
	shorttitle = {{PyGaze}},
	pages = {913--921},
	number = {4},
	journaltitle = {Behavior Research Methods},
	shortjournal = {Behav Res},
	author = {Dalmaijer, Edwin S. and Mathôt, Sebastiaan and Van Der Stigchel, Stefan},
	urldate = {2025-03-31},
	date = {2014-12},
	langid = {english},
}

@article{dalmaijer_pygaze_2014-1,
	title = {{PyGaze}: An open-source, cross-platform toolbox for minimal-effort programming of eyetracking experiments},
	volume = {46},
	issn = {1554-3528},
	url = {https://link.springer.com/10.3758/s13428-013-0422-2},
	doi = {10.3758/s13428-013-0422-2},
	shorttitle = {{PyGaze}},
	pages = {913--921},
	number = {4},
	journaltitle = {Behavior Research Methods},
	shortjournal = {Behav Res},
	author = {Dalmaijer, Edwin S. and Mathôt, Sebastiaan and Van Der Stigchel, Stefan},
	urldate = {2025-03-31},
	date = {2014-12},
	langid = {english},
}

@online{noauthor_pygaze_nodate,
	title = {{PyGaze}: An open-source, cross-platform toolbox for minimal-effort programming of eyetracking experiments {\textbar} Behavior Research Methods},
	url = {https://link.springer.com/article/10.3758/s13428-013-0422-2},
	urldate = {2025-03-31},
}

@article{ossandon_spatial_2014,
	title = {Spatial biases in viewing behavior},
	volume = {14},
	issn = {1534-7362},
	url = {https://doi.org/10.1167/14.2.20},
	doi = {10.1167/14.2.20},
	abstract = {Viewing behavior exhibits temporal and spatial structure that is independent of stimulus content and task goals. One example of such structure is horizontal biases, which are likely rooted in left-right asymmetries of the visual and attentional systems. Here, we studied the existence, extent, and mechanisms of this bias. Left- and right-handed subjects explored scenes from different image categories, presented in original and mirrored versions. We also varied the spatial spectral content of the images and the timing of stimulus onset. We found a marked leftward bias at the start of exploration that was independent of image category. This left bias was followed by a weak bias to the right that persisted for several seconds. This asymmetry was found in the majority of right-handers but not in left-handers. Neither low- nor high-pass filtering of the stimuli influenced the bias. This argues against mechanisms related to the hemispheric segregation of global versus local visual processing. Introducing a delay in stimulus onset after offset of a central fixation spot also had no influence. The bias was present even when stimuli were presented continuously and without any requirement to fixate, associated to both fixation- and saccade-contingent image changes. This suggests the bias is not caused by structural asymmetries in fixation control. Instead the pervasive horizontal bias is compatible with known asymmetries of higher-level attentional areas related to the detection of novel events.},
	pages = {20},
	number = {2},
	journaltitle = {Journal of Vision},
	shortjournal = {Journal of Vision},
	author = {Ossandón, José P. and Onat, Selim and König, Peter},
	urldate = {2024-11-21},
	date = {2014-02-25},
}

@article{foulsham_tom_stable_2018,
	title = {Stable individual differences predict eye movements to the left, but not handedness or line bisection},
	volume = {144},
	issn = {0042-6989},
	url = {https://www.sciencedirect.com/science/article/pii/S0042698918300208},
	doi = {10.1016/j.visres.2018.02.002},
	abstract = {When observers view an image, their initial eye movements are not equally distributed but instead are often biased to the left of the picture. This pa…},
	pages = {38--46},
	journaltitle = {Vision Research},
	author = {{Foulsham, Tom} and {Frost, Emma} and {Sage, Lilly}},
	urldate = {2024-11-25},
	date = {2018-03-01},
	langid = {american},
	note = {Publisher: Pergamon},
}

@inproceedings{muller_celina_l_through_2025,
	title = {Through the Eyes of {OCD}: An Eye-Tracking Study on Attentional Biases Toward Personally Relevant Stimuli},
	eventtitle = {Psychologie und Geist},
	author = {{Müller, Celina L} and {Ehring, Thomas;} and {Kustermann, Andreas;} and {Walter, Alica;} and {Berberich, Götz;} and {Noll-Hussong, Michael;} and {Ehinger, Benedikt V.} and {Cludius, Barbara}},
	date = {2025},
}

@article{durgin_upper-left_2008,
	title = {Upper-left gaze bias reveals competing search strategies in a reverse Stroop task},
	volume = {127},
	issn = {0001-6918},
	url = {https://www.sciencedirect.com/science/article/pii/S0001691807000868},
	doi = {10.1016/j.actpsy.2007.08.007},
	abstract = {Three experiments with a total of 87 human observers revealed an upper-left spatial bias in the initial movement of gaze during visual search. The bias was present whether or not the explicit control of gaze was required for the task. This bias may be part of a search strategy that competed with the fixed-gaze parallel search strategy hypothesized by Durgin [Durgin, F. H. (2003). Translation and competition among internal representations in a reverse Stroop effect. Perception \&Psychophysics, 65, 367–378.] for this task. When the spatial probabilities of the search target were manipulated either in accord with or in opposition to the existing upper-left bias, two orthogonal factors of interference in the latency data were differentially affected. The two factors corresponded to two different forms of representation and search. Target probabilities consistent with the gaze bias encouraged opportunistic serial search (including gaze shifts), while symmetrically opposing target probabilities produced latency patterns more consistent with parallel search based on a sensory code.},
	pages = {428--448},
	number = {2},
	journaltitle = {Acta Psychologica},
	shortjournal = {Acta Psychologica},
	author = {Durgin, Frank H. and Doyle, Erika and Egan, Louisa},
	urldate = {2024-11-21},
	date = {2008-02-01},
	keywords = {Eye-movements, Spatial attention, Spatial bias, Stroop, Upper-left, Visual attention, Visual search},
}

@article{spotorno_whats_2025,
	title = {What's left of the leftward bias in scene viewing? Lateral asymmetries in information processing during early search guidance},
	volume = {254},
	issn = {0010-0277},
	url = {https://www.sciencedirect.com/science/article/pii/S0010027724002956},
	doi = {10.1016/j.cognition.2024.106009},
	shorttitle = {What's left of the leftward bias in scene viewing?},
	abstract = {Understanding how early scene viewing is guided can reveal fundamental brain mechanisms for quickly making sense of our surroundings. Viewing is often initiated from the left side. Across two experiments, we focused on search initiation for lateralised targets within real-world scenes, investigating the role of the cerebral hemispheres in guiding the first saccade. We aimed to disentangle hemispheric contribution from the effects of reading habits and distinguish between an overall dominance of the right hemisphere for visuospatial processing and finer hemispheric specialisation for the type of target template representation (from pictorial versus verbal cues), spatial scale (global versus local), and timescale (short versus longer). We replicated the tendency to initiate search leftward in both experiments. However, we found no evidence supporting a significant impact of left-to-right reading habits, either as a purely motor or attentional bias to the left. A general visuospatial dominance of the right hemisphere could not account for the results either. In Experiment 1, we found a greater probability of directing the first saccade toward targets in the left visual field but only after a verbal target cue, with no lateral differences after a pictorial cue. This suggested a contribution of the right hemisphere specialisation in perceptually simulating words' referents. Lengthening the Inter-Stimulus Interval between the cue and the scene (from 100 to 900 ms) resulted in reduced first saccade gain in the left visual field, suggesting a decreased ability of the the right hemisphere to use the target template to guide gaze close to the target object, which primarily depends on local information processing. Experiment 2, using visual versus auditory verbal cues, replicated and extended the findings for both first saccade direction and gain. Overall, our study shows that the multidetermined functional specialisation of the cerebral hemispheres is a key driver of early scene search and must be incorporated into theories and models to advance understanding of the mechanisms that guide viewing behaviour.},
	pages = {106009},
	journaltitle = {Cognition},
	shortjournal = {Cognition},
	author = {Spotorno, Sara and Tatler, Benjamin W.},
	urldate = {2024-11-24},
	date = {2025-01-01},
	keywords = {Cerebral hemispheres, Eye movements, Functional specialisation, Leftward bias, Reading habits, Real-world scenes, Visual search},
}
