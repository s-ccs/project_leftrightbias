@online{noauthor_about_nodate,
	title = {About – {PyGaze}},
	url = {https://www.pygaze.org/about/},
	urldate = {2025-03-31},
	langid = {british},
}

@article{hooge_adjustment_1998,
	title = {Adjustment of fixation duration in visual search},
	volume = {38},
	issn = {0042-6989},
	url = {https://www.sciencedirect.com/science/article/pii/S0042698997002873},
	doi = {10.1016/s0042-6989(97)00287-3},
	abstract = {To investigate whether fixation durations are adjusted to the duration of a foveal analysis task, we designed a search task in which each stimulus element yielded information about the position of the target. We asked subjects to look for the target by making eye movements in the direction indicated by each stimulus element. We explicitly asked the subjects to make the eye movements in the correct direction, but they did not always do this. They made only 65–80\% of the eye movements in directions indicated by the stimulus elements. From these results we conclude that fixation durations are not solely determined by the immediate visual stimulus and that subjects encounter difficulties when trying to increase fixation durations to values that would enable them to direct saccades accurately. In a second experiment we shortened the presentation time in order to provide an incentive for the subjects to speed up search. Shortening the presentation time did not affect fixation duration. Therefore, we suggest that fixation duration is controlled by a mechanism that uses estimations of the foveal analysis time of previous fixated stimulus elements.},
	pages = {1295--IN4},
	number = {9},
	journaltitle = {Vision Research},
	author = {Hooge, Ignace Th C. and Erkelens, Casper J.},
	date = {1998},
	keywords = {Control of fixation duration, Saccades, Vvisual search},
}

@article{foulsham_asymmetries_2010,
	title = {Asymmetries in the direction of saccades during perception of scenes and fractals: Effects of image type and image features},
	volume = {50},
	issn = {00426989},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0042698910000416},
	doi = {10.1016/j.visres.2010.01.019},
	shorttitle = {Asymmetries in the direction of saccades during perception of scenes and fractals},
	abstract = {The direction in which people tend to move their eyes when inspecting images can reveal the different inﬂuences on eye guidance in scene perception, and their time course. We investigated biases in saccade direction during a memory-encoding task with natural scenes and computer-generated fractals. Images were rotated to disentangle egocentric and image-based guidance. Saccades in fractals were more likely to be horizontal, regardless of orientation. In scenes, the ﬁrst saccade often moved down and subsequent eye movements were predominantly vertical, relative to the scene. These biases were modulated by the distribution of visual features (saliency and clutter) in the scene. The results suggest that image orientation, visual features and the scene frame-of-reference have a rapid effect on eye guidance.},
	pages = {779--795},
	number = {8},
	journaltitle = {Vision Research},
	author = {Foulsham, Tom and Kingstone, Alan},
	urldate = {2019-11-27},
	date = {2010-04},
	langid = {english},
}

@article{barbot_asymmetries_2021,
	title = {Asymmetries in visual acuity around the visual field},
	volume = {21},
	rights = {http://creativecommons.org/licenses/by/4.0/},
	issn = {1534-7362},
	url = {https://jov.arvojournals.org/article.aspx?articleid=2772148},
	doi = {10.1167/jov.21.1.2},
	pages = {2},
	number = {1},
	journaltitle = {Journal of Vision},
	shortjournal = {Journal of Vision},
	author = {Barbot, Antoine and Xue, Shutian and Carrasco, Marisa},
	urldate = {2025-04-24},
	date = {2021-01-04},
	langid = {english},
}

@article{cludius_attentional_2019,
	title = {Attentional biases of vigilance and maintenance in obsessive-compulsive disorder: An eye-tracking study},
	volume = {20},
	issn = {2211-3649},
	url = {https://www.sciencedirect.com/science/article/pii/S2211364917300970},
	doi = {10.1016/j.jocrd.2017.12.007},
	series = {Experimental studies of cognitive processes in {OCD} – new insights and challenges},
	shorttitle = {Attentional biases of vigilance and maintenance in obsessive-compulsive disorder},
	abstract = {Background and objectives
Attentional biases play an important role in the development and maintenance of obsessive-compulsive disorder ({OCD}). Previous studies using reaction time tasks in {OCD} have produced inconsistent results. This is the first study to measure attentional biases in patients with several subtypes of {OCD} using eye tracking.
Methods
Twenty-eight patients with {OCD} and 21 healthy controls were assessed using a free-viewing paradigm, incorporating contamination-related, checking-related, and neutral stimuli. Attentional patterns were measured using an eye tracker. A possible vigilance bias was assessed using entry time, and a possible maintenance bias was assessed using dwell time.
Results
Patients with checking-related symptoms of {OCD} showed a maintenance bias but no vigilance bias in regard to checking-related compared to neutral stimuli. No differences in attention were found in patients with contamination-related symptoms.
Limitations
Internal validity is restricted due to a high overlap between subgroups, the lack of negative (not {OCD}-related) control stimuli, and the absence of a clinical control group.
Conclusions
Patients with checking-related symptoms of {OCD} showed a maintenance bias to checking-related stimuli. Due to methodological limitations, the results should be considered preliminary and need to be replicated before firm conclusions can be drawn.},
	pages = {30--38},
	journaltitle = {Journal of Obsessive-Compulsive and Related Disorders},
	shortjournal = {Journal of Obsessive-Compulsive and Related Disorders},
	author = {Cludius, Barbara and Wenzlaff, Frederike and Briken, Peer and Wittekind, Charlotte E.},
	urldate = {2023-03-15},
	date = {2019-01-01},
	langid = {english},
	keywords = {Attentional bias, Eye movements, Eye tracking, Obsessive-compulsive disorder},
}

@article{skukies_brain_2025,
	title = {Brain responses vary in duration-modeling strategies and challenges},
	volume = {3},
	issn = {2837-6056},
	url = {https://direct.mit.edu/imag/article/doi/10.1162/IMAG.a.1003/133682/Brain-responses-vary-in-duration-modeling},
	doi = {10.1162/IMAG.a.1003},
	abstract = {Abstract Typically, event-related brain responses are calculated invariant to the underlying event duration, even in cases where event durations observably vary: with reaction times, fixation durations, word lengths, or varying stimulus durations. Additionally, an often co-occurring consequence of differing event durations is a variable overlap of the responses to subsequent events. While the problem of overlap, for example, in {fMRI} and {EEG} is successfully addressed using linear overlap correction, it is unclear whether overlap correction and duration covariate modeling can be jointly used, as both are dependent on the same inter-event distance variability. Here, we first show that failing to explicitly account for event durations can lead to spurious results and thus are important to consider. Next, we propose and compare several methods based on multiple regression to explicitly account for stimulus durations. Using simulations, we find that non-linear spline regression of the duration effect outperforms other candidate approaches. Finally, we show that non-linear event duration modeling is compatible with linear overlap correction in time, making mass-univariate models combining non-linear spline regression of duration and linear overlap correction a flexible and appropriate tool to model overlapping brain signals. This allows us to reconcile the analysis of brain responses to stimuli in situations where durations differ between conditions, for example, different reaction times, different stimulus durations, or fixation-related potentials with different fixation durations. While in this paper we focus on {EEG} analyses, we additionally show that our findings generalize to {fMRI} {BOLD} responses, and argue that they should generalize to other overlapping signals such as {LFPs}, or pupil dilation responses.},
	pages = {IMAG.a.1003},
	journaltitle = {Imaging Neuroscience},
	author = {Skukies, René and Schepers, Judith and Ehinger, Benedikt},
	urldate = {2026-01-08},
	date = {2025-11},
	langid = {english},
	keywords = {ourwork, record},
}

@article{Mattingley1994,
	title = {Can task specific perceptual bias be distinguished from unilateral neglect?},
	volume = {32},
	issn = {0028-3932},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/7936164},
	abstract = {The present study examined visuoperceptual bias in 12 right hemisphere damaged patients, eight of whom showed left unilateral neglect on standard clinical tests, and in 30 normal controls. In the chimeric faces task, subjects were required to judge which of a pair of faces appeared happier. Stimuli comprising each pair were mirror images, with the smiling half on the left of one face and on the right of the other. In the grey scales task, subjects were required to indicate which of two shaded rectangles appeared to be darker overall. Again, stimuli were mirror images, with the darker end appearing either on the left or on the right. Patients exhibited a significant rightward bias on both experimental tasks, in contrast to the significant leftward bias exhibited by controls. There was no significant correlation between patients' performances on standard clinical tests and the extent of bias on the two experimental tasks, suggesting that such patients exhibit distinct impairments of spatial cognition which are differentially indexed by the two types of task. Moreover, for both patients and controls, scores obtained on the two perceptual bias tasks were unrelated, suggesting that they may engage stimulus-specific processes which have different underlying patterns of asymmetrical processing. These data provide further support for models which propose that the heterogeneity of disorders of spatial cognition arise from disruption of distinct neural mechanisms.},
	pages = {805--17},
	number = {7},
	journaltitle = {Neuropsychologia},
	author = {Mattingley, J B and Bradshaw, J L and Nettleton, N C and Bradshaw, J a},
	date = {1994-07},
	keywords = {Adult, Aged, Aged, 80 and over, Attention, Attention: physiology, Brain Damage, Chronic, Brain Damage, Chronic: physiopathology, Brain Damage, Chronic: psychology, Discrimination Learning, Discrimination Learning: physiology, Dominance, Cerebral, Dominance, Cerebral: physiology, Female, Hemianopsia, Hemianopsia: physiopathology, Hemianopsia: psychology, Humans, Male, Middle Aged, Neuropsychological Tests, Orientation, Orientation: physiology, Pattern Recognition, Visual, Pattern Recognition, Visual: physiology, Psychomotor Performance, Psychomotor Performance: physiology},
}

@article{fromer_common_2024,
	title = {Common neural choice signals emerge artifactually amidst multiple distinct value signals},
	doi = {10.1038/s41562-024-01971-z},
	pages = {2022.08.02.502393},
	journaltitle = {Nature Human Behaviour},
	author = {Frömer, R. and Nassar, M. R. and Ehinger, Benedikt V. and Shenhav, A.},
	date = {2024},
	langid = {english},
	keywords = {record, whateverwork},
}

@article{mathot_conducting_2022,
	title = {Conducting Linguistic Experiments Online With {OpenSesame} and {OSWeb}},
	volume = {72},
	issn = {0023-8333, 1467-9922},
	url = {https://onlinelibrary.wiley.com/doi/10.1111/lang.12509},
	doi = {10.1111/lang.12509},
	abstract = {Abstract
            In this Methods Showcase Article, we outline a workflow for running behavioral experiments online, with a focus on experiments that rely on presentation of complex stimuli and measurement of reaction times, which includes many psycholinguistic experiments. The workflow that we describe here relies on three tools: {OpenSesame}/{OSWeb} (open source) provides a user‐friendly graphical interface for developing experiments; {JATOS} (open source) is server software for hosting experiments; and Prolific (commercial) is a platform for recruiting participants. These three tools integrate well with each other and together provide a workflow that requires little technical expertise. We discuss, and illustrate through an example study, several challenges that are associated with running online experiments, including temporal precision, the implementation of counterbalancing, data quality, and issues related to privacy and ethics. We conclude that these challenges are real but surmountable, and that in many cases online experiments are a viable alternative to laboratory‐based experiments.},
	pages = {1017--1048},
	number = {4},
	journaltitle = {Language Learning},
	shortjournal = {Language Learning},
	author = {Mathôt, Sebastiaan and March, Jennifer},
	urldate = {2025-03-31},
	date = {2022-12},
	langid = {english},
}

@misc{bertrand_continuous_2023,
	title = {Continuous Measures of Decision-Difficulty Captured Remotely: {II}. Webcam eye-tracking reveals early decision processing},
	url = {http://biorxiv.org/lookup/doi/10.1101/2023.06.06.543799},
	doi = {10.1101/2023.06.06.543799},
	shorttitle = {Continuous Measures of Decision-Difficulty Captured Remotely},
	abstract = {{AbstractAs} decisions require the gathering of relevant information, eye-tracking measures that capture the way visual information is typically acquired offer powerful indices of the dynamic decision-making process. This study is the second of a pair of studies that explore continuous measures of decision-making using remote, online tools in naturalistic settings. While cursor-tracking, used in the companion paper (Ouellette Zuk et al., 2023), enabled access to dynamic decision processes expressed during movement, in the present study, we now employ webcam eye-tracking to examine the dynamics of information gathering during decision making prior to movement initiation. Using three previously published binary choice tasks, we explored indices of decision difficulty in the gaze dynamics that would complement the motor measures in our companion paper. We find that harder choices elicit more eye dwells and longer final dwells, reflecting a decision resolution process that Ouellette Zuk et al. index during the final choice movement. Beyond this, we identify distinct gaze patterns uniquely employed in each task, revealing the utility and sensitivity of gaze metrics in illuminating the early difficulty-independent information gathering processes at play. Together, this paper series demonstrates the power of remote, online methods as tools for deeply understanding the complete, dynamic and continuous decision process, from the first glance to the final response.},
	publisher = {Cold Spring Harbor Laboratory},
	author = {Bertrand, Jennifer K. and Zuk, Alexandra A. Ouellette and Chapman, Craig S.},
	urldate = {2025-07-24},
	date = {2023-06-07},
}

@article{czeszumski_coordinating_2021,
	title = {Coordinating With a Robot Partner Affects Neural Processing Related to Action Monitoring},
	volume = {15},
	issn = {1662-5218},
	doi = {10.3389/fnbot.2021.686010},
	abstract = {Robots start to play a role in our social landscape, and they are progressively becoming responsive, both physically and socially. It begs the question of how humans react to and interact with robots in a coordinated manner and what the neural underpinnings of such behavior are. This exploratory study aims to understand the differences in human-human and human-robot interactions at a behavioral level and from a neurophysiological perspective. For this purpose, we adapted a collaborative dynamical paradigm from the literature. We asked 12 participants to hold two corners of a tablet while collaboratively guiding a ball around a circular track either with another participant or a robot. In irregular intervals, the ball was perturbed outward creating an artificial error in the behavior, which required corrective measures to return to the circular track again. Concurrently, we recorded electroencephalography ({EEG}). In the behavioral data, we found an increased velocity and positional error of the ball from the track in the human-human condition vs. human-robot condition. For the {EEG} data, we computed event-related potentials. We found a significant difference between human and robot partners driven by significant clusters at fronto-central electrodes. The amplitudes were stronger with a robot partner, suggesting a different neural processing. All in all, our exploratory study suggests that coordinating with robots affects action monitoring related processing. In the investigated paradigm, human participants treat errors during human-robot interaction differently from those made during interactions with other humans. These results can improve communication between humans and robot with the use of neural activity in real-time.},
	pages = {686010},
	journaltitle = {Frontiers in Neurorobotics},
	author = {Czeszumski, Artur and Gert, Anna L. and Keshava, Ashima and Ghadirzadeh, Ali and Kalthoff, Tilman and Ehinger, Benedikt V. and Tiessen, Max and Björkman, Mårten and Kragic, Danica and König, Peter},
	urldate = {2023-11-23},
	date = {2021-08},
	keywords = {record, whateverwork},
}

@inproceedings{ehinger_decoding_2023,
	location = {Oxford, {UK}},
	title = {Decoding Accuracies as Well as {ERP} Amplitudes Do Not Show Between-Task Correlations},
	doi = {10.32470/CCN.2023.1029-0},
	booktitle = {2023 Conference on Cognitive Computational Neuroscience},
	publisher = {Cognitive Computational Neuroscience},
	author = {Ehinger, Benedikt V. and Bonasch, Hannes},
	urldate = {2023-11-23},
	date = {2023},
	keywords = {whateverwork},
}

@book{macmillan_detection_2005,
	title = {Detection Theory: A User's Guide},
	isbn = {978-0-8058-4230-2},
	url = {https://books.google.de/books?id=Jbi9nVMrWi8C},
	publisher = {Lawrence Erlbaum Associates},
	author = {Macmillan, N.A. and Creelman, C.D.},
	date = {2005},
	lccn = {2004043261},
}

@book{wickens_elementary_2001,
	title = {Elementary Signal Detection Theory},
	isbn = {978-0-19-535780-6},
	url = {https://books.google.de/books?id=s3pGN_se4v0C},
	publisher = {Oxford University Press},
	author = {Wickens, T.D.},
	date = {2001},
	lccn = {00066540},
}

@article{hernandez_escaping_2017,
	title = {Escaping the corner of death? An eye-tracking study of reading direction influence on attention and memory},
	volume = {34},
	rights = {https://www.emerald.com/insight/site-policies},
	issn = {0736-3761},
	url = {https://www.emerald.com/insight/content/doi/10.1108/JCM-02-2016-1710/full/html},
	doi = {10.1108/JCM-02-2016-1710},
	shorttitle = {Escaping the corner of death?},
	abstract = {Purpose: We examine the effect of location-driven logo placement on attention and memory on the web addressing differences between individuals that read unidirectionally (left-to-right) versus bidirectionally (both right-to-left and left-to-right). Design/methodology/approach: Using an eye-tracking approach combined with traditional verbal measures, we compared attention and memory measures from a sample composed of bidirectional (Arab/English) readers and unidirectional readers. Findings: The findings reveal that unidirectional and bidirectional readers differ in attention patterns. Compared to bidirectional readers, unidirectional readers pay less attention to the logo on the bottom right corner of the webpage based on verbal measures. The eye-tracking data of the two groups further identify differences based on total hits and duration time. Unidirectional left-to-right readers demonstrate higher fluency in feature-based attention whereas bidirectional readers show higher fluency in spatial attention. Research limitations: Individuals from the sampled cultures would have a considerably different mindset regarding exposure to pictorial materials in general. Future research that replicates or extends the current study needs to ensure comparability via both cultural-psychological and demographic analyses. Practical implications: The findings suggest that directional reading bias should be taken into consideration in web design, online advertising and search patterns in an international marketing context.},
	pages = {1--10},
	number = {1},
	journaltitle = {Journal of Consumer Marketing},
	shortjournal = {{JCM}},
	author = {Hernandez, Monica D. and Wang, Yong and Sheng, Hong and Kalliny, Morris and Minor, Michael},
	urldate = {2024-12-02},
	date = {2017-01-09},
	langid = {english},
}

@article{glaholt_evidence_2010,
	title = {Evidence for top-down control of eye movements during visual decision making},
	volume = {10},
	issn = {1534-7362},
	url = {https://doi.org/10.1167/10.5.15},
	doi = {10.1167/10.5.15},
	abstract = {Participants' eye movements were monitored while they viewed displays containing 6 exemplars from one of several categories of everyday items (belts, sunglasses, shirts, shoes), with a column of 3 items presented on the left and another column of 3 items presented on the right side of the display. Participants were either required to choose which of the two sets of 3 items was the most expensive (2-{AFC}) or which of the 6 items was the most expensive (6-{AFC}). Importantly, the stimulus display, and the relevant stimulus dimension, were held constant across conditions. Consistent with the hypothesis of top-down control of eye movements during visual decision making, we documented greater selectivity in the processing of stimulus information in the 6-{AFC} than the 2-{AFC} decision. In addition, strong spatial biases in looking behavior were demonstrated, but these biases were largely insensitive to the instructional manipulation, and did not substantially influence participants' choices.},
	pages = {15},
	number = {5},
	journaltitle = {Journal of Vision},
	shortjournal = {Journal of Vision},
	author = {Glaholt, Mackenzie G. and Wu, Mei-Chun and Reingold, Eyal M.},
	urldate = {2024-11-21},
	date = {2010-05-07},
}

@article{nummenmaa_eye_2006,
	title = {Eye movement assessment of selective attentional capture by emotional pictures.},
	volume = {6},
	issn = {1931-1516, 1528-3542},
	url = {https://doi.apa.org/doi/10.1037/1528-3542.6.2.257},
	doi = {10.1037/1528-3542.6.2.257},
	abstract = {The eye-tracking method was used to assess attentional orienting to and engagement on emotional visual scenes. In Experiment 1, unpleasant, neutral, or pleasant target pictures were presented simultaneously with neutral control pictures in peripheral vision under instruction to compare pleasantness of the pictures. The probability of first fixating an emotional picture, and the frequency of subsequent fixations, were greater than those for neutral pictures. In Experiment 2, participants were instructed to avoid looking at the emotional pictures, but these were still more likely to be fixated first and gazed longer during the first-pass viewing than neutral pictures. Low-level visual features cannot explain the results. It is concluded that overt visual attention is captured by both unpleasant and pleasant emotional content.},
	pages = {257--268},
	number = {2},
	journaltitle = {Emotion},
	shortjournal = {Emotion},
	author = {Nummenmaa, Lauri and Hyönä, Jukka and Calvo, Manuel G.},
	urldate = {2024-11-26},
	date = {2006},
	langid = {english},
}

@article{zhao_eye_2012,
	title = {Eye movements and attention: The role of pre-saccadic shifts of attention in perception, memory and the control of saccades},
	volume = {74},
	issn = {0042-6989},
	url = {https://www.sciencedirect.com/science/article/pii/S0042698912001885},
	doi = {10.1016/j.visres.2012.06.017},
	series = {Visual Attention 2012 Volume I},
	shorttitle = {Eye movements and attention},
	abstract = {Saccadic eye movements and perceptual attention work in a coordinated fashion to allow selection of the objects, features or regions with the greatest momentary need for limited visual processing resources. This study investigates perceptual characteristics of pre-saccadic shifts of attention during a sequence of saccades using the visual manipulations employed to study mechanisms of attention during maintained fixation. The first part of this paper reviews studies of the connections between saccades and attention, and their significance for both saccadic control and perception. The second part presents three experiments that examine the effects of pre-saccadic shifts of attention on vision during sequences of saccades. Perceptual enhancements at the saccadic goal location relative to non-goal locations were found across a range of stimulus contrasts, with either perceptual discrimination or detection tasks, with either single or multiple perceptual targets, and regardless of the presence of external noise. The results show that the preparation of saccades can evoke a variety of attentional effects, including attentionally-mediated changes in the strength of perceptual representations, selection of targets for encoding in visual memory, exclusion of external noise, or changes in the levels of internal visual noise. The visual changes evoked by saccadic planning make it possible for the visual system to effectively use saccadic eye movements to explore the visual environment.},
	pages = {40--60},
	journaltitle = {Vision Research},
	shortjournal = {Vision Research},
	author = {Zhao, Min and Gersch, Timothy M. and Schnitzer, Brian S. and Dosher, Barbara A. and Kowler, Eileen},
	urldate = {2026-01-09},
	date = {2012-12-01},
	keywords = {Attention, Detection, Dual-task performance, Eye movements, Motor planning, Orientation identification, Saccades, Saccadic eye movements, Vision, Visual memory},
}

@article{Nicholls1999,
	title = {Free-viewing perceptual asymmetries for the judgement of brightness, numerosity and size.},
	volume = {37},
	issn = {0028-3932},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/10199644},
	abstract = {Perceptual asymmetries under free-viewing conditions were investigated in 24 normal dextral adults. Three tasks were administered that required participants to chose between a pair of left/right reversed stimuli on the basis of their brightness, numerosity or size. These stimulus features were represented asymmetrically within the stimuli, so that each stimulus appeared darker, larger or more numerous on the left or right sides. Participants more often selected the stimulus with the relevant feature on the left-hand side for all three tasks. Response times for leftward responses were faster than rightward responses. Split-half reliabilities revealed a high level of consistency within the tasks. However, the correlation between tasks was low. These results suggest that the different tasks, while showing similar levels of perceptual asymmetry, engage distinct sets of lateralised processes.},
	pages = {307--14},
	number = {3},
	journaltitle = {Neuropsychologia},
	author = {Nicholls, M E and Bradshaw, J L and Mattingley, J B},
	date = {1999-03},
	keywords = {Adolescent, Adult, Brain asymmetries, Brain asymmetries: attention, Cerebral Cortex, Cerebral Cortex: physiology, Female, Functional Laterality, Humans, Light, Male, Visual Perception, Visual Perception: physiology},
}

@article{hernandez-garcia_global_2020,
	title = {Global visual salience of competing stimuli},
	volume = {20},
	issn = {1534-7362},
	url = {https://doi.org/10.1167/jov.20.7.27},
	doi = {10.1167/jov.20.7.27},
	abstract = {Current computational models of visual salience accurately predict the distribution of fixations on isolated visual stimuli. It is not known, however, whether the global salience of a stimulus, that is, its effectiveness in the competition for attention with other stimuli, is a function of the local salience or an independent measure. Further, do task and familiarity with the competing images influence eye movements? Here, we investigated the direction of the first saccade to characterize and analyze the global visual salience of competing stimuli. Participants freely observed pairs of images while eye movements were recorded. The pairs balanced the combinations of new and already seen images, as well as task and task-free trials. Then, we trained a logistic regression model that accurately predicted the location—left or right image—of the first fixation for each stimulus pair, accounting too for the influence of task, familiarity, and lateral bias. The coefficients of the model provided a reliable measure of global salience, which we contrasted with two distinct local salience models, {GBVS} and Deep Gaze. The lack of correlation of the behavioral data with the former and the small correlation with the latter indicate that global salience cannot be explained by the feature-driven local salience of images. Further, the influence of task and familiarity was rather small, and we reproduced the previously reported left-sided bias. Summarized, we showed that natural stimuli have an intrinsic global salience related to the human initial gaze direction, independent of the local salience and little influenced by task and familiarity.},
	pages = {27},
	number = {7},
	journaltitle = {Journal of Vision},
	shortjournal = {Journal of Vision},
	author = {Hernández-García, Alex and Ramos Gameiro, Ricardo and Grillini, Alessandro and König, Peter},
	urldate = {2024-11-21},
	date = {2020-07-28},
}

@article{yan_humans_2023,
	title = {Humans Predict the Forest, Not the Trees: Statistical Learning of Spatiotemporal Structure in Visual Scenes},
	volume = {33},
	issn = {1047-3211, 1460-2199},
	doi = {10.1093/cercor/bhad115},
	shorttitle = {Humans Predict the Forest, Not the Trees},
	abstract = {Abstract The human brain is capable of using statistical regularities to predict future inputs. In the real world, such inputs typically comprise a collection of objects (e.g. a forest constitutes numerous trees). The present study aimed to investigate whether perceptual anticipation relies on lower-level or higher-level information. Specifically, we examined whether the human brain anticipates each object in a scene individually or anticipates the scene as a whole. To explore this issue, we first trained participants to associate co-occurring objects within fixed spatial arrangements. Meanwhile, participants implicitly learned temporal regularities between these displays. We then tested how spatial and temporal violations of the structure modulated behavior and neural activity in the visual system using {fMRI}. We found that participants only showed a behavioral advantage of temporal regularities when the displays conformed to their previously learned spatial structure, demonstrating that humans form configuration-specific temporal expectations instead of predicting individual objects. Similarly, we found suppression of neural responses for temporally expected compared with temporally unexpected objects in lateral occipital cortex only when the objects were embedded within expected configurations. Overall, our findings indicate that humans form expectations about object configurations, demonstrating the prioritization of higher-level over lower-level information in temporal expectation.},
	pages = {8300--8311},
	number = {13},
	journaltitle = {Cerebral Cortex},
	author = {Yan, Chuyao and Ehinger, Benedikt V and Pérez-Bellido, Alexis and Peelen, Marius V and De Lange, Floris P},
	urldate = {2023-11-23},
	date = {2023-06},
	keywords = {"whateverwork, record"},
}

@article{hirmas_individual_2024,
	title = {Individual and contextual effects of attention in risky choice},
	volume = {27},
	issn = {1386-4157, 1573-6938},
	url = {https://www.cambridge.org/core/journals/experimental-economics/article/individual-and-contextual-effects-of-attention-in-risky-choice/916B4DAB8F4A10D5AE788502929CEB3F},
	doi = {10.1007/s10683-024-09849-7},
	abstract = {We investigate the role of visual attention in risky choice in a rich experimental dataset that includes eye-tracking data. We first show that attention is not reducible to individual and contextual variables, which explain only 20\% of attentional variation. We then decompose attentional variation into individual average attention and trial-wise deviations of attention to capture different cognitive processes. Individual average attention varies by individual, and can proxy for individual preferences or goals (as in models of “rational inattention” or goal-directed attention). Trial-wise deviations of attention vary within subjects and depend on contextual factors (as in models of “salience” or stimulus-driven attention). We find that both types of attention predict behavior: average individual attention patterns are correlated with individual levels of loss aversion and capture part of this individual heterogeneity. Adding trial-wise deviations of attention further improves model fit. Our results show that a decomposition of attention into individual average attention and trial-wise deviations of attention can capture separable cognitive components of decision making and provides a useful tool for economists and researchers from related fields interested in decision-making and attention.},
	pages = {1211--1238},
	number = {5},
	journaltitle = {Experimental Economics},
	author = {Hirmas, Alejandro and Engelmann, Jan B. and Weele, Joël van der},
	urldate = {2025-07-24},
	date = {2024-11},
	langid = {english},
	keywords = {Attention, D81, D83, D87, D91, Eye-tracking, Loss aversion, Random, Utility models},
}

@article{schutz_interindividual_2014,
	title = {Interindividual differences in preferred directions of perceptual and motor decisions},
	volume = {14},
	url = {https://jov.arvojournals.org/article.aspx?articleid=2193903},
	doi = {10.1167/14.12.16},
	pages = {16--16},
	number = {12},
	journaltitle = {Journal of vision},
	publisher = {The Association for Research in Vision and Ophthalmology},
	author = {Schütz, Alexander C.},
	urldate = {2026-01-09},
	date = {2014},
}

@article{ossandon_irrelevant_2015,
	title = {Irrelevant tactile stimulation biases visual exploration in external coordinates},
	volume = {5},
	issn = {2045-2322},
	url = {http://www.nature.com/articles/srep10664},
	doi = {10.1038/srep10664},
	number = {1},
	journaltitle = {Scientific Reports},
	author = {Ossandón, José P. and König, Peter and Heed, Tobias},
	urldate = {2020-03-13},
	date = {2015-09},
	langid = {english},
	note = {10 citations (Semantic Scholar/{DOI}) [2022-10-04]},
}

@article{DellaSala2010,
	title = {Items on the left are better remembered.},
	volume = {63},
	issn = {1747-0226},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/20306371},
	doi = {10.1080/17470211003690672},
	abstract = {Neurologically intact individuals show a spatial processing bias in perception tasks, specifically showing a bias towards the left in bisecting lines. We present evidence for a novel finding that a leftwards bias occurs in short-term memory for recently presented arbitrary bindings of visual features. Three experiments are reported, two of which involve a total of over 60,000 participants with a small number of trials for each. Experiment 3 involved a larger number of trials for each of 144 participants. Participants reproduced from immediate memory arrays of shape-colour-location bindings. In all three experiments, significantly more errors were observed in reproduction of items presented on the right of the array than on the left. Results could not be accounted for by perceptual errors, or by order of presentation or order of reproduction. Findings suggest that items presented on the left are better remembered, indicating a spatial asymmetry in forming or retrieving feature bindings in visual short-term memory.},
	pages = {848--55},
	number = {5},
	journaltitle = {Quarterly journal of experimental psychology},
	author = {Della Sala, Sergio and Darling, Stephen and Logie, Robert H},
	urldate = {2011-07-19},
	date = {2010-05},
	keywords = {80 and over, Adolescent, Adult, Aged, Brain asymmetries, Brain asymmetries: Memory, Discrimination Learning, Discrimination Learning: physiology, Female, Functional Laterality, Functional Laterality: physiology, Humans, Male, Memory, Memory: {STM}, Middle Aged, Neuropsychological Tests, Photic Stimulation, Photic Stimulation: methods, Short-Term, Short-Term: physiology, Space Perception, Space Perception: physiology, Visual Perception, Visual Perception: physiology, Young Adult},
}

@article{Luh1994a,
	title = {Left- and right-handers see people differently: free-vision perceptual asymmetries for chimeric stimuli},
	volume = {25},
	url = {http://www.sciencedirect.com/science/article/pii/S0278262684710281},
	doi = {10.1006/brcg.1994.1028},
	pages = {141--160},
	journaltitle = {Brain and cognition},
	author = {Luh, {KE} and Redl, J and Levy, J},
	urldate = {2014-09-01},
	date = {1994},
}

@article{Foulsham2013,
	title = {Leftward biases in picture scanning and line bisection: a gaze-contingent window study.},
	volume = {78},
	issn = {1878-5646},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/23257282},
	doi = {10.1016/j.visres.2012.12.001},
	abstract = {A bias for humans to attend to the left side of space has been reported in a variety of experiments. While patients with hemispatial neglect mistakenly bisect horizontal lines to the right of centre, neurologically healthy individuals show a mean leftward error. Here, two experiments demonstrated a robust tendency for participants to saccade to the left when viewing photographs. We were able to manipulate this bias by using an asymmetrical gaze-contingent window, which revealed more of the scene on one side of fixation-causing participants to saccade more often in that direction. A second experiment demonstrated the same change in eye movements occurring rapidly from trial to trial, and investigated whether it would carry over and effect attention during a line bisection task. There was some carry-over from gaze-contingent scene viewing to the eye movements during line bisection. However, despite frequent initial eye movements and many errors to the left, manual responses were not affected by this change in orienting. We conclude that the mechanisms underlying asymmetrical attention in picture scanning and line bisection are flexible and can be separated, with saccades in scene perception driven more by a skewed perceptual span.},
	pages = {14--25},
	journaltitle = {Vision research},
	publisher = {Elsevier Ltd},
	author = {Foulsham, Tom and Gray, Alexander and Nasiopoulos, Eleni and Kingstone, Alan},
	urldate = {2014-08-29},
	date = {2013-01-15},
	keywords = {Adolescent, Adult, Analysis of Variance, Attention, Attention: physiology, Female, Humans, Male, Photic Stimulation, Photic Stimulation: methods, Saccades, Saccades: physiology, Visual Perception, Visual Perception: physiology, Young Adult},
}

@article{Buschman2011,
	title = {Neural substrates of cognitive capacity limitations},
	volume = {108},
	doi = {10.1073/pnas.1104666108},
	abstract = {Cognition has a severely limited capacity: Adult humans can retain only about four items “in mind”. This limitation is fundamental to human brain function: Individual capacity is highly correlated with intelligence measures and capacity is reduced in neuropsychiatric diseases. Although human capacity limitations are well studied, their mechanisms have not been investigated at the single-neuron level. Simultaneous recordings from monkey parietal and frontal cortex revealed that visual capacity limitations occurred immedi- ately upon stimulus encoding and in a bottom-up manner. Capacity limitations were found to reflect a dual model of working memory. The left and right halves of visual space had independent capacities and thus are discrete resources. However, within each hemifield, neural information about successfully remembered objects was re- ducedbyaddingfurtherobjects, indicatingthat resources are shared. Together, these results suggest visual capacity limitation is due to discrete, slot-like, resources, each containing limited pools of neural information that can be divided among objects.},
	pages = {11252--11255},
	number = {27},
	journaltitle = {{PNAS}},
	author = {Buschman, Timothy J and Siegel, Markus and Roy, Jefferson E and Miller, Earl K},
	date = {2011},
	keywords = {2011-11-07, Brain asymmetries: Memory, Memory, Memory: {STM}, Memory: mechanisms, pk},
}

@article{mathot_opensesame_2012,
	title = {{OpenSesame}: An open-source, graphical experiment builder for the social sciences},
	volume = {44},
	issn = {1554-3528},
	url = {http://link.springer.com/10.3758/s13428-011-0168-7},
	doi = {10.3758/s13428-011-0168-7},
	shorttitle = {{OpenSesame}},
	pages = {314--324},
	number = {2},
	journaltitle = {Behavior Research Methods},
	shortjournal = {Behav Res},
	author = {Mathôt, Sebastiaan and Schreij, Daniel and Theeuwes, Jan},
	urldate = {2025-03-31},
	date = {2012-06},
	langid = {english},
}

@article{Luh1991,
	title = {Perceptual asymmetries for free viewing of several types of chimeric stimuli.},
	volume = {16},
	issn = {0278-2626},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/1854472},
	abstract = {We examined perceptual biases of right-handers on six free-vision chimeric tasks; two involving a judgement of happiness of a facial expression in photographic and cartoon chimeras, two involving a judgement of femininity in male/female photographic and cartoon chimeras, and two involving a spatial judgement of nonface chimeric stimuli. All four of the face tasks and one of the nonface tasks elicited left spatial field biases of varying magnitudes, and perceptual asymmetries on all tasks were positively correlated. However, multiple correlational analyses revealed that these tests shared differing proportions of variance with each other. Results indicate that, in addition to a common factor or set of factors contributing to lateral biases that is independent of both the nature of the stimulus and whether the stimulus engages lateralized mechanisms, there are distinct lateralized mechanisms which yield different patterns of perceptual asymmetries for different stimuli.},
	pages = {83--103},
	number = {1},
	journaltitle = {Brain and cognition},
	author = {Luh, K E and Rueckert, L M and Levy, J},
	date = {1991-05},
	keywords = {Analysis of Variance, Brain asymmetries, Brain asymmetries: attention, Face, Face: physiology, Female, Functional Laterality, Humans, Male, Photic Stimulation, Task Performance and Analysis, Vision, Vision: faces, Visual Perception, Visual Perception: physiology},
}

@article{churches_perceptual_2017,
	title = {Perceptual biases in the horizontal and vertical dimensions are driven by separate cognitive mechanisms},
	volume = {70},
	issn = {1747-0226},
	doi = {10.1080/17470218.2015.1131841},
	abstract = {Perceptual attention in healthy participants is characterized by two biases, one operating in the horizontal plane, which draws attention leftward, and the other operating in the vertical plane, which draws attention upward. Given that these biases are reliably found in the same individual, and appear similar at a surface level, a number of researchers have investigated the relationship between horizontal and vertical attentional biases. To date, these investigations have failed to find an association, and this may be due to the fact that one-dimensional vertical and horizontal stimuli were presented separately rather than being measured from a single, two-dimensional stimulus. Across three experiments, two dimensional stimuli were presented, and participants marked the centre of the stimuli. In addition, the shapes of the stimuli were manipulated to determine whether this produced the same modulation of the two biases. Across 13 stimuli and three experiments there were no correlations between the vertical and horizontal biases. In addition, manipulations of stimulus shape, which affected biases in one dimension, did not affect biases in the other dimension. There were, however, consistent correlations between the degree of bias within each dimension across the different stimuli. This study has produced converging evidence that horizontal and vertical biases in spatial judgments rely on separate cognitive mechanisms. To account for these results we discuss a model whereby horizontal asymmetries rely more on space-based mechanisms whereas vertical asymmetries rely more on object-based mechanisms.},
	pages = {444--460},
	number = {3},
	journaltitle = {Quarterly Journal of Experimental Psychology (2006)},
	shortjournal = {Q J Exp Psychol (Hove)},
	author = {Churches, Owen and Loetscher, Tobias and Thomas, Nicole A. and Nicholls, Michael E. R.},
	date = {2017-03},
	keywords = {Adolescent, Adult, Attention, Bias, Cognition, Female, Humans, Line bisection, Male, Middle Aged, Object, Orientation, Photic Stimulation, Reaction Time, Space, Space Perception, Statistics as Topic, Young Adult},
}

@article{nikolaev_planning_2023,
	title = {Planning to Revisit: Neural Activity in Refixation Precursors},
	volume = {23},
	issn = {1534-7362},
	doi = {10.1167/jov.23.7.2},
	shorttitle = {Planning to Revisit},
	pages = {2},
	number = {7},
	journaltitle = {Journal of Vision},
	author = {Nikolaev, Andrey R. and Ehinger, Benedikt V. and Meghanathan, Radha Nila and Van Leeuwen, Cees},
	urldate = {2023-11-23},
	date = {2023-07},
	keywords = {record, whateverwork},
}

@article{himmelberg_polar_2023,
	title = {Polar angle asymmetries in visual perception and neural architecture},
	volume = {46},
	issn = {01662236},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0166223623000681},
	doi = {10.1016/j.tins.2023.03.006},
	pages = {445--458},
	number = {6},
	journaltitle = {Trends in Neurosciences},
	shortjournal = {Trends in Neurosciences},
	author = {Himmelberg, Marc M. and Winawer, Jonathan and Carrasco, Marisa},
	urldate = {2025-04-24},
	date = {2023-06},
	langid = {english},
}

@article{Jewell2000,
	title = {Pseudoneglect: a review and meta-analysis of performance factors in line bisection tasks.},
	volume = {38},
	issn = {0028-3932},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/10617294},
	abstract = {An exhaustive qualitative (vote-counting) review is conducted of the literature concerning visual and non-visual line bisection in neurologically normal subject populations. Although most of these studies report a leftward bisection error (i.e., pseudoneglect), considerable between-study variability and inconsistency characterize this literature. A meta-analysis of this same literature is performed in which the total quantitative data set, comprising 73 studies (or sub-studies) and 2191 subjects, is analyzed with respect to 26 performance factors. The meta-analytic results indicate a significant leftward bisection error in neurologically normal subjects, with an overall effect size of between -0.37 and -0.44 (depending on integration method), which is significantly modulated to varying degrees by a number of additional task or subject variables. For example, visual bisection tasks, midsagittal-pointing tasks and tactile bisection tasks all lead to leftward errors, while kinesthetic tasks result in rightward errors. Tachistoscopic forced-choice testing methods reveal much greater estimates of bisection error (effect size = -1.32) than do manual method-of-adjustment procedures (effect size= -0.40). Subject age significantly modulates line bisection performance such that older subjects err significantly rightward compared to younger subjects, and to veridical line midpoint. Male subjects make slightly larger leftward errors than do female subjects. Handedness has a small effect on bisection errors, with dextrals erring slightly further to the left than sinistral subjects. The hand used to perform manual bisection tasks modulated performance, where use of the left hand lead to greater leftward errors than those obtained using the right hand. One of the most significant factors modulating bisection error is the direction in which subjects initiate motor scanning (with either eye or hand), where a left-to-right scan pattern leads to large leftward errors while a right-to-left scan pattern leads to rightward errors.},
	pages = {93--110},
	number = {1},
	journaltitle = {Neuropsychologia},
	author = {Jewell, G and {McCourt}, M E},
	date = {2000},
	keywords = {Adult, Aged, Attention, Attention: physiology, Brain Mapping, Brain asymmetries, Brain asymmetries: attention, Cerebral, Cerebral: physiology, Dominance, Female, Functional Laterality, Functional Laterality: physiology, Humans, Male, Middle Aged, Neglect, Neuropsychological Tests, Perceptual Disorders, Perceptual Disorders: diagnosis, Perceptual Disorders: physiopathology, Perceptual Disorders: psychology, Pseudoneglect, Psychomotor Performance, Psychomotor Performance: physiology, Space Perception, Space Perception: physiology},
}

@article{peirce_psychopy2_2019,
	title = {{PsychoPy}2: Experiments in behavior made easy},
	volume = {51},
	issn = {1554-3528},
	url = {http://link.springer.com/10.3758/s13428-018-01193-y},
	doi = {10.3758/s13428-018-01193-y},
	shorttitle = {{PsychoPy}2},
	pages = {195--203},
	number = {1},
	journaltitle = {Behavior Research Methods},
	shortjournal = {Behav Res},
	author = {Peirce, Jonathan and Gray, Jeremy R. and Simpson, Sol and {MacAskill}, Michael and Höchenberger, Richard and Sogo, Hiroyuki and Kastman, Erik and Lindeløv, Jonas Kristoffer},
	urldate = {2025-03-31},
	date = {2019-02},
	langid = {english},
}

@article{dalmaijer_pygaze_2014,
	title = {{PyGaze}: An open-source, cross-platform toolbox for minimal-effort programming of eyetracking experiments},
	volume = {46},
	issn = {1554-3528},
	url = {https://link.springer.com/10.3758/s13428-013-0422-2},
	doi = {10.3758/s13428-013-0422-2},
	shorttitle = {{PyGaze}},
	pages = {913--921},
	number = {4},
	journaltitle = {Behavior Research Methods},
	shortjournal = {Behav Res},
	author = {Dalmaijer, Edwin S. and Mathôt, Sebastiaan and Van Der Stigchel, Stefan},
	urldate = {2025-03-31},
	date = {2014-12},
	langid = {english},
}

@article{dalmaijer_pygaze_2014-1,
	title = {{PyGaze}: An open-source, cross-platform toolbox for minimal-effort programming of eyetracking experiments},
	volume = {46},
	issn = {1554-3528},
	url = {https://link.springer.com/10.3758/s13428-013-0422-2},
	doi = {10.3758/s13428-013-0422-2},
	shorttitle = {{PyGaze}},
	pages = {913--921},
	number = {4},
	journaltitle = {Behavior Research Methods},
	shortjournal = {Behav Res},
	author = {Dalmaijer, Edwin S. and Mathôt, Sebastiaan and Van Der Stigchel, Stefan},
	urldate = {2025-03-31},
	date = {2014-12},
	langid = {english},
}

@online{noauthor_pygaze_nodate,
	title = {{PyGaze}: An open-source, cross-platform toolbox for minimal-effort programming of eyetracking experiments {\textbar} Behavior Research Methods},
	url = {https://link.springer.com/article/10.3758/s13428-013-0422-2},
	urldate = {2025-03-31},
}

@article{dimigen_regression-based_2021,
	title = {Regression-Based Analysis of Combined {EEG} and Eye-Tracking Data: Theory and Applications},
	volume = {21},
	issn = {1534-7362},
	doi = {10.1167/jov.21.1.3},
	shorttitle = {Regression-Based Analysis of Combined {EEG} and Eye-Tracking Data},
	pages = {3--3},
	number = {1},
	journaltitle = {Journal of Vision},
	publisher = {The Association for Research in Vision and Ophthalmology},
	author = {Dimigen, Olaf and Ehinger, Benedikt V.},
	urldate = {2021-01-17},
	date = {2021-01},
	keywords = {read, whateverwork},
}

@article{Dickinson2009,
	title = {Spatial asymmetries in viewing and remembering scenes: Consequences of an attentional bias?},
	volume = {71},
	url = {http://link.springer.com/article/10.3758/APP.71.6.1251},
	doi = {10.3758/APP},
	pages = {1251--1262},
	number = {6},
	journaltitle = {Attention, Perception, \& Psychophysics},
	author = {Dickinson, {CA} and Intraub, H},
	urldate = {2014-08-29},
	date = {2009},
	keywords = {⚠️ Invalid {DOI}},
}

@article{dickinson_spatial_2009,
	title = {Spatial asymmetries in viewing and remembering scenes: Consequences of an attentional bias?},
	volume = {71},
	issn = {1943-393X},
	doi = {10.3758/APP.71.6.1251},
	shorttitle = {Spatial asymmetries in viewing and remembering scenes},
	abstract = {Given a single fixation, memory for scenes containing salient objects near both the left and right view boundaries exhibited a rightward bias in boundary extension (Experiment 1). On each trial, a 500-msec picture and 2.5-sec mask were followed by a boundary adjustment task. Observers extended boundaries 5\% more on the right than on the left. Might this reflect an asymmetric distribution of attention? In Experiments 2A and 2B, free viewing of pictures revealed that first saccades were more often leftward (62\%) than rightward (38\%). In Experiment 3, 500-msec pictures were interspersed with 2.5-sec masks. A subsequent object recognition memory test revealed better memory for left-side objects. Scenes were always mirror reversed for half the observers, thus ruling out idiosyncratic scene compositions as the cause of these asymmetries. Results suggest an unexpected leftward bias of attention that selectively enhanced the representations, causing a smaller boundary extension error and better object memory on the views’ left sides. ({PsycINFO} Database Record (c) 2016 {APA}, all rights reserved)},
	pages = {1251--1262},
	number = {6},
	journaltitle = {Attention, Perception, \& Psychophysics},
	publisher = {Psychonomic Society},
	author = {Dickinson, Christopher A. and Intraub, Helene},
	date = {2009},
	note = {Place: {US}},
	keywords = {Attention, Consequence, Memory, Object Recognition, Spatial Perception},
}

@article{ossandon_spatial_2014,
	title = {Spatial biases in viewing behavior},
	volume = {14},
	issn = {1534-7362},
	url = {https://doi.org/10.1167/14.2.20},
	doi = {10.1167/14.2.20},
	abstract = {Viewing behavior exhibits temporal and spatial structure that is independent of stimulus content and task goals. One example of such structure is horizontal biases, which are likely rooted in left-right asymmetries of the visual and attentional systems. Here, we studied the existence, extent, and mechanisms of this bias. Left- and right-handed subjects explored scenes from different image categories, presented in original and mirrored versions. We also varied the spatial spectral content of the images and the timing of stimulus onset. We found a marked leftward bias at the start of exploration that was independent of image category. This left bias was followed by a weak bias to the right that persisted for several seconds. This asymmetry was found in the majority of right-handers but not in left-handers. Neither low- nor high-pass filtering of the stimuli influenced the bias. This argues against mechanisms related to the hemispheric segregation of global versus local visual processing. Introducing a delay in stimulus onset after offset of a central fixation spot also had no influence. The bias was present even when stimuli were presented continuously and without any requirement to fixate, associated to both fixation- and saccade-contingent image changes. This suggests the bias is not caused by structural asymmetries in fixation control. Instead the pervasive horizontal bias is compatible with known asymmetries of higher-level attentional areas related to the detection of novel events.},
	pages = {20},
	number = {2},
	journaltitle = {Journal of Vision},
	shortjournal = {Journal of Vision},
	author = {Ossandón, José P. and Onat, Selim and König, Peter},
	urldate = {2024-11-21},
	date = {2014-02-25},
}

@article{ossandon_spatial_2014-1,
	title = {Spatial biases in viewing behavior},
	volume = {14},
	issn = {1534-7362},
	url = {http://jov.arvojournals.org/Article.aspx?doi=10.1167/14.2.20},
	doi = {10.1167/14.2.20},
	pages = {20--20},
	number = {2},
	journaltitle = {Journal of Vision},
	author = {Ossandon, J. P. and Onat, S. and Konig, P.},
	urldate = {2020-03-13},
	date = {2014-02-25},
	langid = {english},
	note = {80 citations (Semantic Scholar/{DOI}) [2022-10-04]},
}

@article{foulsham_stable_2018,
	title = {Stable individual differences predict eye movements to the left, but not handedness or line bisection},
	volume = {144},
	issn = {00426989},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0042698918300208},
	doi = {10.1016/j.visres.2018.02.002},
	abstract = {When observers view an image, their initial eye movements are not equally distributed but instead are often biased to the left of the picture. This pattern has been linked to pseudoneglect, the spatial bias to the left that is observed in line bisection and a range of other perceptual and attentional tasks. Pseudoneglect is often explained according to the dominance of the right-hemisphere in the neural control of attention, a view bolstered by diﬀerences between left- and right-handed participants in both line bisection and eye movements. We re-examined this observation in eighty participants (half of whom reported being left handed) who completed a computerised line bisection task and viewed a series of images. We failed to replicate the previously-reported eﬀect of handedness on eye movements in image viewing, with both groups showing a large average bias to the left on the ﬁrst saccade. While there was a modest eﬀect of handedness on line bisection, there was no correlation between the two tasks. Stable individual diﬀerences, as well as a shorter latency on the initial saccade, were robust predictors of an initial saccade to the left. Therefore, while there seems to be a reﬂexive and idiosyncratic drive to look to the left, it is not well accounted for by handedness and may have diﬀerent mechanisms from other forms of pseudoneglect.},
	pages = {38--46},
	journaltitle = {Vision Research},
	shortjournal = {Vision Research},
	author = {Foulsham, Tom and Frost, Emma and Sage, Lilly},
	urldate = {2025-04-11},
	date = {2018-03},
	langid = {english},
}

@article{foulsham_tom_stable_2018,
	title = {Stable individual differences predict eye movements to the left, but not handedness or line bisection},
	volume = {144},
	issn = {0042-6989},
	url = {https://www.sciencedirect.com/science/article/pii/S0042698918300208},
	doi = {10.1016/j.visres.2018.02.002},
	abstract = {When observers view an image, their initial eye movements are not equally distributed but instead are often biased to the left of the picture. This pa…},
	pages = {38--46},
	journaltitle = {Vision Research},
	publisher = {Pergamon},
	author = {{Foulsham, Tom} and {Frost, Emma} and {Sage, Lilly}},
	urldate = {2024-11-25},
	date = {2018-03-01},
	langid = {american},
}

@article{mikheev_art_2024,
	title = {The Art of Brainwaves: A Survey on Event-Related Potential Visualization Practices},
	volume = {4},
	rights = {http://creativecommons.org/licenses/by/4.0},
	issn = {2957-3963},
	url = {https://apertureneuro.org/article/116386-the-art-of-brainwaves-a-survey-on-event-related-potential-visualization-practices},
	doi = {10.52294/001c.116386},
	shorttitle = {The Art of Brainwaves},
	abstract = {Electroencephalography ({EEG}) and event-related potentials ({ERPs}) have been analyzed for more than 70 years. Yet, we know little about how practitioners visualize the results of their analyses. Here, we designed an online survey (n=213) targeting M/{EEG} practitioners from novice to expert level. Our primary goal is to better understand the visualization tools currently in use, the challenges researchers face, and their experiences and opinions on how best to display their brain data. Finally, we explored whether researchers are aware of more general visualization issues related to visualization of uncertainty and color maps. In this paper, we provide an overview of the most popular {ERP} visualization tools. Additionally, we found that the community does not have a unique nomenclature to refer to some plot types, and we propose a set of recommendations to name the most popular {ERP} plot types. Finally, we provide an analysis of practitioner feature preferences for software developers and conclude with further recommendations for {ERP} practitioners.},
	journaltitle = {Aperture Neuro},
	author = {Mikheev, Vladimir and Skukies, Rene and Ehinger, Benedikt V.},
	urldate = {2026-01-08},
	date = {2024-04},
	langid = {english},
	keywords = {record, whateverwork},
}

@article{fiedler_dynamics_2012,
	title = {The Dynamics of Decision Making in Risky Choice: An Eye-Tracking Analysis},
	volume = {3},
	issn = {1664-1078},
	url = {http://journal.frontiersin.org/article/10.3389/fpsyg.2012.00335/abstract},
	doi = {10.3389/fpsyg.2012.00335},
	shorttitle = {The Dynamics of Decision Making in Risky Choice},
	journaltitle = {Frontiers in Psychology},
	shortjournal = {Front. Psychology},
	publisher = {Frontiers Media {SA}},
	author = {Fiedler, Susann and Glöckner, Andreas},
	urldate = {2025-07-24},
	date = {2012},
}

@inproceedings{skukies_effect_2023,
	location = {Oxford, {UK}},
	title = {The Effect of Estimation Time Window Length on Overlap Correction in {EEG} Data},
	doi = {10.32470/CCN.2023.1229-0},
	booktitle = {2023 Conference on Cognitive Computational Neuroscience},
	publisher = {Cognitive Computational Neuroscience},
	author = {Skukies, René and Ehinger, Benedikt V.},
	urldate = {2023-11-23},
	date = {2023},
	keywords = {record, whateverwork},
}

@inproceedings{muller_celina_l_through_2025,
	title = {Through the Eyes of {OCD}: An Eye-Tracking Study on Attentional Biases Toward Personally Relevant Stimuli},
	eventtitle = {Psychologie und Geist},
	author = {{Müller, Celina L} and {Ehring, Thomas;} and {Kustermann, Andreas;} and {Walter, Alica;} and {Berberich, Götz;} and {Noll-Hussong, Michael;} and {Ehinger, Benedikt V.} and {Cludius, Barbara}},
	date = {2025},
}

@article{Nuthmann2014,
	title = {Time course of pseudoneglect in scene viewing},
	volume = {52},
	issn = {19738102},
	url = {http://dx.doi.org/10.1016/j.cortex.2013.11.007},
	doi = {10.1016/j.cortex.2013.11.007},
	abstract = {When we view the visual world, our eyes move from one location to another about three times each second. When looking at pictures of natural scenes, neurologically intact individuals show a leftward bias in the direction of their first eye movement. The present study investigates the time course of this pseudoneglect and how it depends on task-related control. Eye movements were recorded from 72 participants, each viewing 135 scenes under three different viewing instructions (memorization, esthetic preference judgment, object-in-scene search). In the memorization and preference tasks, pseudoneglect had a maximum extent of about 1° and lasted for about 1500msec, or 5 fixations. The effect was somewhat reduced in the preference task, which gave subjects free reign to fixate anywhere they wanted to. During scene search, a task that is guided primarily by top-down control, observers also showed a distinct pseudoneglect. Strikingly, a leftward bias was present even when the search object was located in the right hemispace. Search performance was not affected by the observed spatial asymmetries. The effects likely arise from a right-hemisphere dominance for visuo-spatial attention. © 2013 Elsevier Ltd.},
	pages = {113--119},
	number = {1},
	journaltitle = {Cortex},
	publisher = {Elsevier Ltd},
	author = {Nuthmann, Antje and Matthias, Ellen},
	date = {2014},
	keywords = {Attention, Eye movements, Hemispheric asymmetry, Pseudoneglect, Scene perception},
}

@article{ehinger_unfold_2019,
	title = {Unfold: An Integrated Toolbox for Overlap Correction, Non-Linear Modeling, and Regression-Based {EEG} Analysis},
	volume = {7},
	issn = {2167-8359},
	doi = {10.7717/peerj.7838},
	shorttitle = {Unfold},
	abstract = {Electrophysiological research with event-related brain potentials ({ERPs}) is increasingly moving from simple, strictly orthogonal stimulation paradigms towards more complex, quasi-experimental designs and naturalistic situations that involve fast, multisensory stimulation and complex motor behavior. As a result, electrophysiological responses from subsequent events often overlap with each other. In addition, the recorded neural activity is typically modulated by numerous covariates, which influence the measured responses in a linear or non-linear fashion. Examples of paradigms where systematic temporal overlap variations and low-level confounds between conditions cannot be avoided include combined electroencephalogram ({EEG})/eye-tracking experiments during natural vision, fast multisensory stimulation experiments, and mobile brain/body imaging studies. However, even “traditional,” highly controlled {ERP} datasets often contain a hidden mix of overlapping activity (e.g., from stimulus onsets, involuntary microsaccades, or button presses) and it is helpful or even necessary to disentangle these components for a correct interpretation of the results. In this paper, we introduce unfold, a powerful, yet easy-to-use {MATLAB} toolbox for regression-based {EEG} analyses that combines existing concepts of massive univariate modeling (“regression-{ERPs}”), linear deconvolution modeling, and non-linear modeling with the generalized additive model into one coherent and flexible analysis framework. The toolbox is modular, compatible with {EEGLAB} and can handle even large datasets efficiently. It also includes advanced options for regularization and the use of temporal basis functions (e.g., Fourier sets). We illustrate the advantages of this approach for simulated data as well as data from a standard face recognition experiment. In addition to traditional and non-conventional {EEG}/{ERP} designs, unfold can also be applied to other overlapping physiological signals, such as pupillary or electrodermal responses. It is available as open-source software at http://www.unfoldtoolbox.org.},
	pages = {e7838},
	journaltitle = {{PeerJ}},
	publisher = {{PeerJ} Inc.},
	author = {Ehinger, Benedikt V. and Dimigen, Olaf},
	urldate = {2020-08-05},
	date = {2019-10},
	keywords = {read, related, whateverwork},
}

@misc{ehinger_unfoldjl_2025,
	title = {Unfold.jl: event-related regression toolbox},
	rights = {{MIT} License},
	url = {https://zenodo.org/doi/10.5281/zenodo.5759066},
	doi = {10.5281/ZENODO.5759066},
	shorttitle = {Unfold.jl},
	abstract = {Unfold v0.8.8 Diff since v0.8.7},
	publisher = {Zenodo},
	author = {Ehinger, Benedikt},
	urldate = {2026-01-08},
	date = {2025-10},
	keywords = {record, whateverwork},
}

@article{mikheev_unfoldmakiejl_2025,
	title = {{UnfoldMakie}.jl: {EEG}/{ERP} visualization package},
	volume = {10},
	rights = {http://creativecommons.org/licenses/by/4.0/},
	issn = {2475-9066},
	url = {https://joss.theoj.org/papers/10.21105/joss.07560},
	doi = {10.21105/joss.07560},
	shorttitle = {{UnfoldMakie}.jl},
	pages = {7560},
	number = {105},
	journaltitle = {Journal of Open Source Software},
	author = {Mikheev, Vladimir and Ehinger, Benedikt},
	urldate = {2025-09-15},
	date = {2025-01},
	keywords = {record, whateverwork},
}

@article{schepers_unfoldsimjl_2025,
	title = {{UnfoldSim}.jl: Simulating continuous event-based time series data for {EEG} and beyond},
	volume = {10},
	rights = {http://creativecommons.org/licenses/by/4.0/},
	issn = {2475-9066},
	url = {https://joss.theoj.org/papers/10.21105/joss.06641},
	doi = {10.21105/joss.06641},
	shorttitle = {{UnfoldSim}.jl},
	pages = {6641},
	number = {107},
	journaltitle = {Journal of Open Source Software},
	author = {Schepers, Judith and Lips, Luis and Marathe, Maanik and Ehinger, Benedikt V.},
	urldate = {2025-09-15},
	date = {2025-03},
	keywords = {ourwork, record},
}

@inproceedings{ehinger_unmixed_2019,
	location = {Berlin, Germany},
	title = {Unmixed: Linear Mixed Models Combined with Overlap Correction for M/{EEG} Analyses. An Extension to the Unfold Toolbox},
	doi = {10.32470/CCN.2019.1102-0},
	shorttitle = {Unmixed},
	booktitle = {2019 Conference on Cognitive Computational Neuroscience},
	publisher = {Cognitive Computational Neuroscience},
	author = {Ehinger, Benedikt V.},
	urldate = {2023-12-07},
	date = {2019},
	keywords = {whateverwork},
}

@article{durgin_upper-left_2008,
	title = {Upper-left gaze bias reveals competing search strategies in a reverse Stroop task},
	volume = {127},
	issn = {0001-6918},
	url = {https://www.sciencedirect.com/science/article/pii/S0001691807000868},
	doi = {10.1016/j.actpsy.2007.08.007},
	abstract = {Three experiments with a total of 87 human observers revealed an upper-left spatial bias in the initial movement of gaze during visual search. The bias was present whether or not the explicit control of gaze was required for the task. This bias may be part of a search strategy that competed with the fixed-gaze parallel search strategy hypothesized by Durgin [Durgin, F. H. (2003). Translation and competition among internal representations in a reverse Stroop effect. Perception \&Psychophysics, 65, 367–378.] for this task. When the spatial probabilities of the search target were manipulated either in accord with or in opposition to the existing upper-left bias, two orthogonal factors of interference in the latency data were differentially affected. The two factors corresponded to two different forms of representation and search. Target probabilities consistent with the gaze bias encouraged opportunistic serial search (including gaze shifts), while symmetrically opposing target probabilities produced latency patterns more consistent with parallel search based on a sensory code.},
	pages = {428--448},
	number = {2},
	journaltitle = {Acta Psychologica},
	shortjournal = {Acta Psychologica},
	author = {Durgin, Frank H. and Doyle, Erika and Egan, Louisa},
	urldate = {2024-11-21},
	date = {2008-02-01},
	keywords = {Eye-movements, Spatial attention, Spatial bias, Stroop, Upper-left, Visual attention, Visual search},
}

@article{gilbert_visual_1973,
	title = {Visual asymmetry in perception of faces},
	volume = {11},
	issn = {0028-3932},
	url = {https://www.sciencedirect.com/science/article/pii/0028393273900493},
	doi = {10.1016/0028-3932(73)90049-3},
	abstract = {Several tests examined the established finding that the right side of the human face has greater saliency in the sense that it seems to bear a greater resemblance to the whole face. An experimental manipulation (photographic reversal of the face) showed that the effect is due to asymmetrical left-field perceptual bias rather than to qualities of faces themselves. Right-hemisphere specialization for facial recognition, coupled with more direct image transfer from the left visual field to the right hemisphere, is suggested as an explanation. No general bias was found for left-handers. Additional data from Hebrew readers do not support an alternate explanation of scanning habits developed through reading.
Résumé
On a examiné sur plusieurs tests le fait antérieurement établi que le côté droit du visage humain a une plus grande saillance, c'est-à-dire qu'il semble comporter une plus grande ressemblance avec la totalité du visage. Une manipulation expérimentale (inversion photographique du visage) a montré que cet effet est dû à un biais perceptif par asymétrie du champ gauche plutôt qu'aux qualités des visages eux-mêmes. La spécialisation de l'hémisphére droit pour la reconnaissance du visage humain en même temps que le transfer de l'image, plus direct du champ gauche á l'hémisphére droit est suggéré en tant qu'explication. Chez les gauchers aucun biais de ce type n'a été constaté. Des données additionnelles obtenues chez des lecteurs hébreux ne sont pas en faveur d'une autre explication par les habitudes de balayage qui se seraient développées grâce à la lecture.
Zusammenfassung
Mit mehreren Tests wurde die eingeführte Feststellung geprüft, die besagt, daß die rechte Seite des menschlichen Gesichts stärker hervortritt, in dem Sinn, daß sie eine großere Ähnlichkeit mit dem Gesamtgesicht aufzuweisen scheint. Eine experimentelle Manipulation (fotographische Umkehr der beiden Gesichtshälften) zeigte, daß diese Wirkung der asymmetrischen Bevorzugung des linken Gesichtsfeldes zuzuschreiben ist und nicht den Eigenarten der Gesichtshälften. Die Spezialisierung der rechten Hemisphäre für die Gesichtserkennung verbunden mit einer direkteren Bildübertragung vom linken Gesichtsfeld zur rechten Hemisphäre wird als Erklärung vorgeschlagen. Es wurde bei Linkshändern keine allgemeine Bevorzugung gefunden. Zusätzliche Daten von Hebräisch-Lesern geben keine Stütze für eine wechselseitige Erklärung von Blickgewegungsgewohnheiten, die durch das Lesen entwickelt wären.},
	pages = {355--362},
	number = {3},
	journaltitle = {Neuropsychologia},
	shortjournal = {Neuropsychologia},
	author = {Gilbert, Christopher and Bakan, Paul},
	urldate = {2026-01-09},
	date = {1973-07-01},
}

@article{Du2010,
	title = {Visual field asymmetry in attentional capture},
	volume = {72},
	issn = {1090-2147},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/19913344},
	doi = {10.1016/j.bandc.2009.10.006},
	abstract = {The present study examined the spatial distribution of involuntary attentional capture over the two visual hemi-fields. A new experiment, and an analysis of three previous experiments showed that distractors in the left visual field that matched a sought-for target in color produced a much larger capture effect than identical distractors in the right visual field, revealing a visual field asymmetry in color-based contingent capture. On the other hand, abrupt onsets in the two hemi-fields did not differ in the magnitude of their capture effect, indicating a symmetric distribution of onset capture. The different spatial patterns for contingent capture and onset capture reveal differences between the two types of attentional capture, possibly indicating differences in the underlying brain mechanisms.},
	pages = {310--6},
	number = {2},
	journaltitle = {Brain and cognition},
	publisher = {Elsevier Inc.},
	author = {Du, Feng and Abrams, Richard A},
	urldate = {2011-08-05},
	date = {2010-03},
	keywords = {Analysis of Variance, Attention, Brain asymmetries, Brain asymmetries: attention, Color, Functional Laterality, Humans, Photic Stimulation, Psychophysics, Reaction Time, Spatial Behavior, Task Performance and Analysis, Visual Perception},
}

@article{krajbich_visual_2010,
	title = {Visual fixations and the computation and comparison of value in simple choice},
	volume = {13},
	rights = {http://www.springer.com/tdm},
	issn = {1097-6256, 1546-1726},
	url = {https://www.nature.com/articles/nn.2635},
	doi = {10.1038/nn.2635},
	pages = {1292--1298},
	number = {10},
	journaltitle = {Nature Neuroscience},
	shortjournal = {Nat Neurosci},
	publisher = {Springer Science and Business Media {LLC}},
	author = {Krajbich, Ian and Armel, Carrie and Rangel, Antonio},
	urldate = {2025-07-24},
	date = {2010-10},
	langid = {english},
}

@article{spotorno_whats_2025,
	title = {What's left of the leftward bias in scene viewing? Lateral asymmetries in information processing during early search guidance},
	volume = {254},
	issn = {0010-0277},
	url = {https://www.sciencedirect.com/science/article/pii/S0010027724002956},
	doi = {10.1016/j.cognition.2024.106009},
	shorttitle = {What's left of the leftward bias in scene viewing?},
	abstract = {Understanding how early scene viewing is guided can reveal fundamental brain mechanisms for quickly making sense of our surroundings. Viewing is often initiated from the left side. Across two experiments, we focused on search initiation for lateralised targets within real-world scenes, investigating the role of the cerebral hemispheres in guiding the first saccade. We aimed to disentangle hemispheric contribution from the effects of reading habits and distinguish between an overall dominance of the right hemisphere for visuospatial processing and finer hemispheric specialisation for the type of target template representation (from pictorial versus verbal cues), spatial scale (global versus local), and timescale (short versus longer). We replicated the tendency to initiate search leftward in both experiments. However, we found no evidence supporting a significant impact of left-to-right reading habits, either as a purely motor or attentional bias to the left. A general visuospatial dominance of the right hemisphere could not account for the results either. In Experiment 1, we found a greater probability of directing the first saccade toward targets in the left visual field but only after a verbal target cue, with no lateral differences after a pictorial cue. This suggested a contribution of the right hemisphere specialisation in perceptually simulating words' referents. Lengthening the Inter-Stimulus Interval between the cue and the scene (from 100 to 900 ms) resulted in reduced first saccade gain in the left visual field, suggesting a decreased ability of the the right hemisphere to use the target template to guide gaze close to the target object, which primarily depends on local information processing. Experiment 2, using visual versus auditory verbal cues, replicated and extended the findings for both first saccade direction and gain. Overall, our study shows that the multidetermined functional specialisation of the cerebral hemispheres is a key driver of early scene search and must be incorporated into theories and models to advance understanding of the mechanisms that guide viewing behaviour.},
	pages = {106009},
	journaltitle = {Cognition},
	shortjournal = {Cognition},
	author = {Spotorno, Sara and Tatler, Benjamin W.},
	urldate = {2024-11-24},
	date = {2025-01-01},
	keywords = {Cerebral hemispheres, Eye movements, Functional specialisation, Leftward bias, Reading habits, Real-world scenes, Visual search},
}

@article{gert_wildlab_2022,
	title = {{WildLab}: A Naturalistic Free Viewing Experiment Reveals Previously Unknown Electroencephalography Signatures of Face Processing},
	volume = {56},
	rights = {© 2022 The Authors. European Journal of Neuroscience published by Federation of European Neuroscience Societies and John Wiley \& Sons Ltd.},
	issn = {1460-9568},
	doi = {10.1111/ejn.15824},
	shorttitle = {{WildLab}},
	abstract = {Neural mechanisms of face perception are predominantly studied in well-controlled experimental settings that involve random stimulus sequences and fixed eye positions. Although powerful, the employed paradigms are far from what constitutes natural vision. Here, we demonstrate the feasibility of ecologically more valid experimental paradigms using natural viewing behaviour, by combining a free viewing paradigm on natural scenes, free of photographer bias, with advanced data processing techniques that correct for overlap effects and co-varying non-linear dependencies of multiple eye movement parameters. We validate this approach by replicating classic N170 effects in neural responses, triggered by fixation onsets (fixation event-related potentials [{fERPs}]). Importantly, besides finding a strong correlation between both experiments, our more natural stimulus paradigm yielded smaller variability between subjects than the classic setup. Moving beyond classic temporal and spatial effect locations, our experiment furthermore revealed previously unknown signatures of face processing: This includes category-specific modulation of the event-related potential ({ERP})'s amplitude even before fixation onset, as well as adaptation effects across subsequent fixations depending on their history.},
	pages = {6022--6038},
	number = {11},
	journaltitle = {European Journal of Neuroscience},
	author = {Gert, Anna L. and Ehinger, Benedikt V. and Timm, Silja and Kietzmann, Tim C. and König, Peter},
	urldate = {2023-11-23},
	date = {2022},
	keywords = {event-related potentials ({ERPs}), eye movements, face processing, fixation-related potentials, natural images, record, whateverwork},
}
